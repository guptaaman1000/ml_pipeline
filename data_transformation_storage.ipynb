{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07340203-c345-497f-b6de-621f26b2bebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Configure logging\n",
    "LOGS_PATH = \"logs/\"\n",
    "os.makedirs(LOGS_PATH, exist_ok=True)\n",
    "logging.basicConfig(filename=os.path.join(LOGS_PATH, 'data_transformation.log'), level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define paths\n",
    "PROCESSED_DATA_PATH = \"processed_data/\"\n",
    "DB_PATH = \"database/churn_data.db\"\n",
    "os.makedirs(\"database\", exist_ok=True)\n",
    "LATEST_DATE = datetime.now().strftime('%Y-%m-%d')\n",
    "KAGGLE_CLEANED_DATA = os.path.join(PROCESSED_DATA_PATH, \"Kaggle_cleaned.csv\")\n",
    "HUGGINGFACE_CLEANED_DATA = os.path.join(PROCESSED_DATA_PATH, \"Hugging Face_cleaned.csv\")\n",
    "\n",
    "# Load datasets\n",
    "def load_data(file_path, source):\n",
    "    if not os.path.exists(file_path):\n",
    "        logging.error(f\"{source} dataset not found at {file_path}\")\n",
    "        return None\n",
    "    df = pd.read_csv(file_path)\n",
    "    logging.info(f\"Loaded {source} dataset with {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
    "    return df\n",
    "\n",
    "# Feature engineering\n",
    "def feature_engineering(df):\n",
    "    if 'tenure' in df.columns and 'MonthlyCharges' in df.columns:\n",
    "        df['TotalSpend'] = df['tenure'] * df['MonthlyCharges']  # Example feature\n",
    "    return df\n",
    "\n",
    "# Normalize numerical features\n",
    "def normalize_features(df):\n",
    "    scaler = MinMaxScaler()\n",
    "    num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "    return df\n",
    "\n",
    "# Store transformed data into SQLite\n",
    "def store_in_database(df, table_name, db_path=DB_PATH):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "    conn.close()\n",
    "    logging.info(f\"Stored transformed data in {table_name} table.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    kaggle_df = load_data(KAGGLE_CLEANED_DATA, \"Kaggle\")\n",
    "    hf_df = load_data(HUGGINGFACE_CLEANED_DATA, \"Hugging Face\")\n",
    "    \n",
    "    for source, df in zip([\"Kaggle\", \"Hugging Face\"], [kaggle_df, hf_df]):\n",
    "        if df is not None:\n",
    "            df = feature_engineering(df)\n",
    "            df = normalize_features(df)\n",
    "            store_in_database(df, f\"{source.replace(' ', '_')}_transformed\")\n",
    "    \n",
    "    logging.info(\"Data transformation completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e9d853-eb14-4f9e-a902-3e31f5e4eda3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
